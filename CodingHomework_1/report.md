### Report - Coding Homework 1

#### 1.数据预处理

本次作业全部使用python进行数据处理和计算，采用numpy库和matpllotlib库来辅助数据处理。

首先需要读取csv文件，对csv文件的读取封装为DataLoader类。本次作业数据的csv文件使用`';'`分隔列，并使用`','`作为小数点，因此用python的csv模块读取数据并不方便。因此直接手动读取数据，将所有的`','`替换为小数点`'.'`，并使用`';'`分隔列，将数据文件中的17列数据分隔出来，便于后面进行处理。

本次作业共有四个数据文件，四个文件中的一起训练。在读取文件时，将标题去掉，存入`self.title`，然后将四个数据文件中从第二行开始的数据拼接在一起，得到全部的数据`self.data`。

对于第二问的逻辑回归推测路面情况，数据`x`为前14列，标签`y`为第15列；第三问的高斯生成模型，数据`x`为前14列，标签`y`为第17列。提取出对应的数据并转化成`np.ndarray`，然后针对此部分进行针对性的数据预处理。包括：给`x`前面插入一列1，代表bias；将`y`转化为onehot向量；对`x`进行scale，全部放缩到`[0, 1]`内。

随机划分训练集和测试集，划分比例为训练集80%测试集20%。首先生成[1, N]的index列表，然后使用`np.random.shuffle`打乱，取前80%的index的数据作为训练数据，其余作为测试数据。这几步操作的效果为随机选出80%的数据作为训练集，其余作为测试集。



#### 2.使用逻辑回归推测路面情况

如第一问所述进行数据预处理。

直接用输入x参与运算，即取函数变换$\phi(x) = x$，核函数$k(x, x') = x^Tx'$。由于路面情况共有三种情况，因此本题为多元逻辑回归。多元逻辑回归的模型为：

$$y = softmax(w^Tx) = \frac {exp(w^Tx)}{\sum(exp(w^Tx))}$$

多元逻辑回归的损失函数为交叉熵，计算公式为：

$$E = -\sum\sum(t_{nj}ln(y_{nj}))$$

对数据采用批量梯度下降，每次对所有样本参与计算。梯度计算和更新公式为：

$$dw = (y - t)^T x$$

$$w = w - \alpha \times dw$$

其中alpha为学习率。初始学习率设置为0.0001，为避免振荡，在epoch >= 100时进行学习率衰减，每10个epoch衰减为原来的0.95。loss的迭代结果为：

<img src='LogisticRegression.png'>

可以看出在epoch = 250左右模型就已经收敛，loss稳定在13335。用得到的权重矩阵w进行测试，对划分的测试集进行预测，并与标注进行对比，以分类准确率accuracy作为最终评价指标，得到的结果为：

$$accuracy = 0.7087339743589743$$



#### 3.高斯概率生成模型推测驾驶风格是否为"Aggressive Style"

对于生成模型，对于每个样本，我们计算得到后验概率，即分类为ci的概率为：

$$p(c1|x) = \frac {p(x|c1)p(c1)}{\sum p(x|ci)p(ci)} = \frac {p(x|c1)p(c1)}{p(x|c1)p(c1) + p(x|c2)p(c2)}$$

对于二元高斯概率生成模型，我们假设似然函数满足高斯概率分布，即：

$$p(x|ci) = \frac 1 {(2\pi)^{\frac 1 2} |\Sigma|^{\frac N 2}}exp\left(-(x - \mu_i)^T\Sigma^{-1}(x-\mu_i)\right)$$

其中$\mu$和$\Sigma$的值由训练样本得到，满足：

$$\mu_i = \frac 1 {N_i} \sum x^{(n)}\{t^{(n)}==i\} = \frac {\sum x^{(n)}\{t^{(n)}==i\}}{\sum \{t^{(n)}==i\}}$$

$$\Sigma = \frac 1 N \sum(x^{(i)} - \mu_{y^{(i)}})(x^{(i)} - \mu_{y^{(i)}})^T$$

同时先验函数满足：

$$p(ci) = \frac 1 N{\sum \{t^{(n)}==i\}}$$

计算出先验函数和似然函数之后，对于每一个测试样本x，都可以计算出分类为c1和c0的后验概率，后验概率较大的为最终的判定结果。使用分类准确率accuracy作为最终评价指标，得到的结果为：

$$accuracy = 0.8595753205128205$$



#### 4.reference:

https://www.jiqizhixin.com/articles/2018-12-24-13

https://blog.csdn.net/sinat_29957455/article/details/86552811

