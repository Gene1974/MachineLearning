### Report - Coding Homework 1

#### 1.数据预处理

本次作业全部使用 python 进行数据处理和计算，采用 numpy 库和 matpllotlib 库来辅助数据处理。

首先读取 csv 文件，对 csv 文件的读取封装为 DataLoader 类。由于 csv 文件格式固定，直接手动读取数据，使用`','`分隔列，得到数据。将数据的标题存入`self.title`，从第二行开始的数据部分存入`self.data`。其中数据`x`为前14列，标签`y`为第15列

数据预处理的内容包括将提取出的对应的数据转化成`np.ndarray`，给`x`前面插入一列1，代表bias；将`y`转化为onehot向量；对`x`进行scale，全部放缩到`[0, 1]`内。
对于非数值数据，建立字典，将不同类型映射到自然数空间。

使用 bootstrap 方法随机重采样得到训练集，没有被采样过的样本作为测试集，划分比例为训练集80%测试集20%。首先生成[1, N]的index列表，然后使用`np.random.shuffle`打乱，取前80%的index的数据作为训练数据，其余作为测试数据。这几步操作的效果为随机选出80%的数据作为训练集，其余作为测试集。



#### 2.随机森林

随机森林中树的数量 $B$ 选择为$B = 10$，每次构建树的数量选择为特征的数量 M 取对数向上取整，即 $m = log_2M + 1 = 4$。

构建 B 棵完全独立的决策树，决策树的构建采用 ID3算法。

最终实现的决策树为 tree = (index, value_dict)，是一个嵌套结构。index 表示当前节点的特征是第几个特征，value_dict 是一个字典，key 为对应特征的不同取值，当取值对应的子节点为叶子节点时，对应 value 为预测值 True 或 False，当取值对应的子节点不为叶子节点时，对应 value 为下一层 tree 的元组 (index, value_dict)，嵌套得到最终树的实现。

如某次训练得到的决策树为：

```python
(2, {2016: (6, {0: (8, {0: (7, {0: False}), 1: False, 2: False, 3: False, 4: False, 5: False, 6: False}), 1: False}), 2017: False, 2018: True, 2012: False, 2013: False, 2014: False, 2015: False})
```

多棵决策树一起构成随机森林。



#### 3.测试

对于每个测试样本，使用前面得到的随机森林的每一棵树进行预测，得到的结果中分类最多的那一类为此样本最终的预测类。

使用分类准确率accuracy作为最终评价指标。

由于使用 bootstrap 划分数据集，因此每次数据集的划分并不均匀，因此进行五次实验，得到的结果为：

| 次数 | accuracy           |
| ---- | ------------------ |
| 1    | 0.6600771456123433 |
| 2    | 0.707764705882353  |
| 3    | 0.648              |
| 4    | 0.6744853997127812 |
| 5    | 0.7404543257612373 |
| 平均 | 0.686156315393743  |

可以看出，在五次实验中，我们的随机森林都可以达到65%-75%的准确率，平均准确率可以达到69%，最高的时候可以达到74%。



